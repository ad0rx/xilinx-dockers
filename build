#!/usr/bin/env bash
#
# New flow for building the base image for Bus Defender. You end up
# with a running container which has ws_tester.py installed and is
# runnable.
#######################################################################

# Exit on error
set -e

LOG=${HOME}/00_docker_build
DOCKER=/usr/bin/docker

# Name and Email used for git config
GIT_NAME="Brad Whitlock"
GIT_EMAIL="bradley.whitlock@peraton.com"

NETWORK="none"
HOSTNAME="dkr-2022"
IMAGE_ROOT="vivado/2022.2"
IMAGE_VERSION="003"
IMAGE_NAME="${IMAGE_ROOT}:${IMAGE_VERSION}"
CONTAINER_NAME="$(echo $IMAGE_NAME | sed s/:/-/g | sed s!/!-!g)"

# ws_tester support
HC_ATTACK_ZIP="/home/brad/Downloads/hc-attack-hardcider-2018.zip"
TESTING_FRAMEWORK_ZIP="/home/brad/Downloads/testing-framework-master.zip"

# Path on local machine to the extracted vivado unified installer
# This path will be mounted to /vivado_extracted inside the container
VIVADO_EXTRACTED="/mnt/BACKUP/archive/xilinx/Xilinx_Unified_2022.2_1014_8888"

# Dir on the host. Mapped to /xilinx_install_dir in the container
XILINX_INSTALL_DIR="/xilinx_docker_installs"

# Path on local machine to where projects root. Will be mounted to
# /projects in container
PROJECTS_PATH="/home/brad/projects"

function build_image () {

    local script_dir=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" \
                  &> /dev/null && pwd )
    cd ${script_dir}

    # Build the image
    DOCKER_BUILDKIT=1                       \
                   $DOCKER build             \
                   --tag ${IMAGE_NAME}      \
                   --build-arg UNAME=$USER  \
                   --build-arg GIT_NAME="$GIT_NAME" \
                   --build-arg GIT_EMAIL=$GIT_EMAIL \
                   --build-arg UID=$(id -u) \
                   --build-arg GID=$(id -g) \
                   -f Dockerfile . | tee -a ${LOG}

}

# if this script is invoked with any argument, you get network=host,
# otherwise no network
function run_container () {

    NETWORK=none
    CPU_SHARES=1024
    if [ -n "$1" ]
    then

        NETWORK=host
        echo "Setting NETWORK=$NETWORK"

        #CPU_SHARES=128
        #echo "Setting CPU_SHARES=$CPU_SHARES"

    fi

    # This directory resides on the host; not within the container
    if [ ! -e ${XILINX_INSTALL_DIR} ]
    then
        echo "Creating ${XILINX_INSTALL_DIR}" | tee -a ${LOG}
        mkdir -p -mode=777 ${XILINX_INSTALL_DIR}
        chown -R ${USER}:docker ${XILINX_INSTALL_DIR}
        chmod g+s ${XILINX_INSTALL_DIR}
    fi

    echo "Starting Container" | tee -a ${LOG}

        # Run the image / create container
# -v /home:/home                                   \
# -v "${HOME}/.Xauthority:/${HOME}/.Xauthority:rw" \
            $DOCKER run -itd --hostname=${HOSTNAME} --env "DISPLAY" \
                   --privileged                                     \
                   --network=${NETWORK}                             \
                   -e HOME=${HOME} -w ${HOME}                       \
                   --mount type=bind,src=/tmp/.X11-unix,dst=/tmp/.X11-unix \
                   --mount type=bind,src=/home/brad/.Xauthority,dst=/home/brad/.Xauthority \
                   --mount type=bind,src=${PROJECTS_PATH},dst=/projects                \
                   --mount type=bind,src=${XILINX_INSTALL_DIR},dst=/xilinx_install_dir \
                   --mount type=bind,src=${VIVADO_EXTRACTED},dst=/vivado_extracted     \
                   --rm --cpu-shares=${CPU_SHARES}                  \
                   --cpus=4                                         \
                   --name ${CONTAINER_NAME}                         \
                   ${IMAGE_NAME} | tee -a ${LOG}

}

function add_vivado () {

    # We check to determine if we need to do this, and we don't check
    # other steps such as add_ws_tester because the vivado
    # installation is not kept within the container, and ws_tester is
    # kept in the container. So, if this is a new build, which is the
    # use case, then we can correctly assume that ws_tester is not
    # installed. However, the vivado install is kept as data on an
    # external drive, because it's huge etc. That means it can persist
    # between builds of the docker image, thus we check if it's
    # already installed.
    if [ ! -e ${XILINX_INSTALL_DIR}/Vivado/2022.2/settings64.sh ]
    then

        # Allow root@dkr to make windows in local user's window manager
        xhost +
        $DOCKER exec -it -w              \
               /vivado_extracted         \
               ${CONTAINER_NAME} ./xsetup

    else

        echo
        cat <<EOF
It appears that Vivado 2022.2 may already be installed
because ${XILINX_INSTALLS_DIR}/Vivado/2022.2/settings64.sh
exists. Skipping the installation of Vivado.
EOF

    fi

}

#######################################################################
#######################################################################

function image_exists () {

    local d=$($DOCKER image ls | \
                  egrep "${IMAGE_ROOT}[ ]+${IMAGE_VERSION}" )

    if [ -z "$d" ]
    then
        # we need to build
        echo "0"
    else
        # image already exists
        echo "1"
    fi

}

echo "Running" | tee ${LOG}

# Begin Main Execution
build_image
run_container with_networking
add_vivado
